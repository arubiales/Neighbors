{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbors \n",
    "\n",
    "Here we are going to see Neighbors Algorithms for Classification and Regression. Neighbors Algorithms try to do predictive analysis measuring the distancen between each data, This algorithms are not good with medium/big amounts of data because for each new data in our dataset we have to compute again all the distances between the points and the new points, so it's computationally very expensive.    \n",
    "\n",
    "For this purpose we are going to use the well-known datasets of Boston and Breast Cancer that are in sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston, load_breast_cancer\n",
    "from sklearn.metrics import f1_score, confusion_matrix, r2_score, mean_squared_error, classification_report, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Load and Preprocess Dataset for regression and classifications problem\n",
    "Here we are going to load to datasets Boston and Breast Cancer.\n",
    "\n",
    "#### Boston\n",
    "It's a Dataset to predict the cost of the Bostons houses based in m2, location, etc. The price have been divided by 10.000\n",
    "\n",
    "#### Breast Cancer\n",
    "This dataset are measurements of different kinds of tumors and we have to predict if it's cancer or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_cancer = StandardScaler()\n",
    "scaler_boston = StandardScaler()\n",
    "dataset_boston = load_boston()\n",
    "dataset_breast_cancer = load_breast_cancer()\n",
    "df_boston = pd.DataFrame(data=dataset_boston['data'], columns=[dataset_boston['feature_names']])\n",
    "df_boston_target = pd.DataFrame(dataset_boston['target'], columns=['target'])\n",
    "df_boston = pd.merge(df_boston, df_boston_target, left_index=True, right_index=True)\n",
    "\n",
    "df_breast_cancer = pd.DataFrame(data=dataset_breast_cancer['data'], columns=[dataset_breast_cancer['feature_names']])\n",
    "df_breast_target = pd.DataFrame(dataset_breast_cancer['target'], columns=['target'])\n",
    "df_breast_cancer = pd.merge(df_breast_cancer, df_breast_target, left_index=True, right_index=True)\n",
    "\n",
    "train_test_boston = train_test_split(df_boston)\n",
    "train_test_cancer = train_test_split(df_breast_cancer)\n",
    "boston_X_train = train_test_boston[0].drop(columns='target')\n",
    "boston_X_train_scale = pd.DataFrame(scaler_boston.fit_transform(boston_X_train), columns= boston_X_train.columns)\n",
    "boston_y_train = train_test_boston[0]['target']\n",
    "boston_X_test = train_test_boston[1].drop(columns='target')\n",
    "boston_X_test_scale = pd.DataFrame(scaler_boston.transform(boston_X_test), columns= boston_X_test.columns)\n",
    "boston_y_test = train_test_boston[1]['target']\n",
    "cancer_X_train = train_test_cancer[0].drop(columns='target')\n",
    "cancer_X_train_scale = pd.DataFrame(scaler_cancer.fit_transform(cancer_X_train), columns= cancer_X_train.columns)\n",
    "cancer_y_train = train_test_cancer[0]['target']\n",
    "cancer_X_test = train_test_cancer[1].drop(columns='target')\n",
    "cancer_X_test_scale = pd.DataFrame(scaler_cancer.transform(cancer_X_test), columns= cancer_X_test.columns)\n",
    "cancer_y_test = train_test_cancer[1]['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Classification\n",
    "The operation of this algorithm is very simple. When a new data come into the algorithm, the algorithm see the N points around this new data and create a vote, in this case if a patient have breast cancer or not, if are more points around the new point that are labeled as cancer then the cancer wins, and this patient will be classified as a Patient with cancer, if there are more points around the new data without cancer, the new point will be classified as no cancer.\n",
    "\n",
    "As we can see, in contrast with tree based models here we need to standardize the variables to achieve better results\n",
    "\n",
    "### Hyperparamns\n",
    "* n_neighbors: the number of points that the algorithm have to see in order to classify data, more points more time needed to make the calculations\n",
    "* weights: the ponderation in the vote of points, could be\n",
    "    * uniform: one point, one vote\n",
    "    * distance: the points more near of the new point to predict his vote have more value\n",
    "* Algorithm: the algorithm that will compute the distances\n",
    "    * brute: it's use a brute-force search wich means that our algorithm will compute all the distances between all points\n",
    "    * kd_tree: it's recommended if we have a medium data dataset. Based on trees the idea of this algorithm is simple, if we know that a point **A** is very distant from point **B** and point **B** very close to point **C** then we know that points **A** and **C** are very distant. This saves us computer time.\n",
    "    * ball_tree: it's very simmilar to kd_tree but works better if we have a big dataset\n",
    "    * auto: the algorithm will choose the best kernel for our dataset.\n",
    "* P: the function that compute the distance, could be:\n",
    "    * 1: Mikowski distance\n",
    "    * 2: Euclidean Distance\n",
    "* leaf_size: if you choose a kernel based on trees, then you can set the number of leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION IN TRAIN\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " [[145   2]\n",
      " [ 10 269]]\n",
      "\n",
      "F1 SCORE:\n",
      " 0.9781818181818182\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       147\n",
      "           1       0.99      0.96      0.98       279\n",
      "\n",
      "    accuracy                           0.97       426\n",
      "   macro avg       0.96      0.98      0.97       426\n",
      "weighted avg       0.97      0.97      0.97       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "KN_class_1 = KNeighborsClassifier()\n",
    "KN_class_1.fit(cancer_X_train_scale, cancer_y_train)\n",
    "preds_train = KN_class_1.predict(cancer_X_train_scale)\n",
    "print('CLASSIFICATION IN TRAIN')\n",
    "print()\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(preds_train, cancer_y_train))\n",
    "print()\n",
    "print('F1 SCORE:\\n', f1_score(preds_train, cancer_y_train))\n",
    "print()\n",
    "print('CLASSIFICATION REPORT\\n',classification_report(preds_train, cancer_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION IN TRAIN\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " [[55  0]\n",
      " [ 2 86]]\n",
      "\n",
      "F1 SCORE:\n",
      " 0.9885057471264368\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        55\n",
      "           1       1.00      0.98      0.99        88\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.98      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_test = KN_class_1.predict(cancer_X_test_scale)\n",
    "print('CLASSIFICATION IN TRAIN')\n",
    "print()\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(preds_test, cancer_y_test))\n",
    "print()\n",
    "print('F1 SCORE:\\n', f1_score(preds_test, cancer_y_test))\n",
    "print()\n",
    "print('CLASSIFICATION REPORT\\n',classification_report(preds_test, cancer_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let try to improve the accuracy of our model with param tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION IN TRAIN\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " [[155   0]\n",
      " [  0 271]]\n",
      "\n",
      "F1 SCORE:\n",
      " 1.0\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       155\n",
      "           1       1.00      1.00      1.00       271\n",
      "\n",
      "    accuracy                           1.00       426\n",
      "   macro avg       1.00      1.00      1.00       426\n",
      "weighted avg       1.00      1.00      1.00       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "KN_class_2 = KNeighborsClassifier(n_neighbors=3,\n",
    "                                  algorithm='brute',\n",
    "                                  p=1,\n",
    "                                  weights='distance',\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "KN_class_2.fit(cancer_X_train_scale, cancer_y_train)\n",
    "preds_train = KN_class_2.predict(cancer_X_train_scale)\n",
    "print('CLASSIFICATION IN TRAIN')\n",
    "print()\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(preds_train, cancer_y_train))\n",
    "print()\n",
    "print('F1 SCORE:\\n', f1_score(preds_train, cancer_y_train))\n",
    "print()\n",
    "print('CLASSIFICATION REPORT\\n',classification_report(preds_train, cancer_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION IN TRAIN\n",
      "\n",
      "CONFUSION MATRIX:\n",
      " [[56  0]\n",
      " [ 1 86]]\n",
      "\n",
      "F1 SCORE:\n",
      " 0.9942196531791908\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        56\n",
      "           1       1.00      0.99      0.99        87\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_test = KN_class_2.predict(cancer_X_test_scale)\n",
    "print('CLASSIFICATION IN TRAIN')\n",
    "print()\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(preds_test, cancer_y_test))\n",
    "print()\n",
    "print('F1 SCORE:\\n', f1_score(preds_test, cancer_y_test))\n",
    "print()\n",
    "print('CLASSIFICATION REPORT\\n',classification_report(preds_test, cancer_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great we have improve our accuracy in 1% with only 1 fail in 143 datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Regression\n",
    "Is very similar to the classification algorithm so we only are going to do the regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE in train: 2.3253825857519788\n",
      "MSE in train: 3.59266828907933\n",
      "MAE in test: 3.2366929133858267\n",
      "RMSE in test: 5.923985942658785\n"
     ]
    }
   ],
   "source": [
    "KN_reg_1 = KNeighborsRegressor()\n",
    "\n",
    "KN_reg_1.fit(boston_X_train_scale, boston_y_train)\n",
    "train_predictions = KN_reg_1.predict(boston_X_train_scale)\n",
    "test_predictions = KN_reg_1.predict(boston_X_test_scale)\n",
    "print('MAE in train:', mean_absolute_error(train_predictions, boston_y_train))\n",
    "print('MSE in train:', np.sqrt(mean_squared_error(train_predictions, boston_y_train)))\n",
    "print('MAE in test:', mean_absolute_error(test_predictions, boston_y_test))\n",
    "print('RMSE in test:', np.sqrt(mean_squared_error(test_predictions, boston_y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE in train: 0.0\n",
      "MSE in train: 0.0\n",
      "MAE in test: 2.907951599903701\n",
      "RMSE in test: 5.007447640755706\n"
     ]
    }
   ],
   "source": [
    "KN_reg_2 = KNeighborsRegressor(n_neighbors=3,\n",
    "                               algorithm='brute',\n",
    "                               p=1,\n",
    "                               weights='distance',\n",
    "                               n_jobs=-1)\n",
    "\n",
    "KN_reg_2.fit(boston_X_train_scale, boston_y_train)\n",
    "train_predictions = KN_reg_2.predict(boston_X_train_scale)\n",
    "test_predictions = KN_reg_2.predict(boston_X_test_scale)\n",
    "print('MAE in train:', mean_absolute_error(train_predictions, boston_y_train))\n",
    "print('MSE in train:', np.sqrt(mean_squared_error(train_predictions, boston_y_train)))\n",
    "print('MAE in test:', mean_absolute_error(test_predictions, boston_y_test))\n",
    "print('RMSE in test:', np.sqrt(mean_squared_error(test_predictions, boston_y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target    5.0\n",
      "dtype: float64\n",
      "target    50.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_boston_target.min())\n",
    "print(df_boston_target.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have improve our model reducing the MAE in test in more than 3.000€ and the RMSE in almost 10.000€ it's not a very good model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
